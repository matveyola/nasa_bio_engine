{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ec8607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b73e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d82a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xslx = pd.read_excel(\"../data/articles_with_full_text_20251004_105527.xlsx\")\n",
    "df_xslx.to_csv(\"../data/exmpl_for_clustering.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7fb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 17:23:58,923 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "2025-10-04 17:24:02,157 - BERTopic - Embedding - Completed ✓\n",
      "2025-10-04 17:24:02,158 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-10-04 17:24:02,207 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-10-04 17:24:02,228 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-10-04 17:24:02,279 - BERTopic - Cluster - Completed ✓\n",
      "2025-10-04 17:24:02,298 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-10-04 17:24:02,318 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [microgravity, bone, cell, space, cells, increased, including, stem, loss, osteolysis]\n",
      "1    [microgravity, bone, cell, space, cells, increased, including, stem, loss, osteolysis]\n",
      "2    [microgravity, bone, cell, space, cells, increased, including, stem, loss, osteolysis]\n",
      "Name: topic_keywords, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"../data/exmpl_for_clustering.csv\")\n",
    "docs = df[\"abstract\"].fillna(\"\").astype(str)\n",
    "docs_list = docs[docs.str.strip() != \"\"].tolist()           \n",
    "N = len(docs_list)\n",
    "if N < 3:\n",
    "    raise ValueError(f\"Занадто мало документів (N={N}). Додай текстів ≥3–5.\")\n",
    "\n",
    "\n",
    "nn = max(2, min(15, N - 1))\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=nn,\n",
    "    n_components=2,\n",
    "    metric=\"cosine\",\n",
    "    init=\"random\",\n",
    "    random_state=42,\n",
    ")\n",
    "mcs = max(2, min(10, max(2, N // 2)))   \n",
    "ms  = max(1, min(5, N - 1))            \n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=mcs,\n",
    "    min_samples=ms,\n",
    "    metric=\"euclidean\",                 \n",
    "    cluster_selection_method=\"eom\",\n",
    "    prediction_data=False               \n",
    ")\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# У НАС ГОТОВІ ЕМБЕДДИНГИ, ТОМУ ПОТРІБНО БУДЕ ПЕРЕПИСАТИ\n",
    "# embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=None,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model = hdbscan_model,\n",
    "    verbose=True,\n",
    "    vectorizer_model=vectorizer_model\n",
    ")\n",
    "\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs_list)\n",
    "\n",
    "# 5) Ключові слова теми для кожної статті\n",
    "def topic_keywords_list(t, top_n=10):\n",
    "    # if t == -1:\n",
    "        # return [\"Other\"]\n",
    "    words = topic_model.get_topic(t) or []\n",
    "    return [w for w, _ in words[:top_n]] if words else [\"Other\"]\n",
    "\n",
    "# Якщо треба рядок, заміни на: \", \".join(topic_keywords_list(t))\n",
    "topic_kw = [topic_keywords_list(t, top_n=10) for t in topics]\n",
    "\n",
    "# 6) Повертаємо в df (зберігаючи первісні індекси)\n",
    "df = df.loc[docs.index].copy()\n",
    "df[\"topic_id\"] = topics\n",
    "df[\"topic_keywords\"] = topic_kw\n",
    "\n",
    "print(df[\"topic_keywords\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
